{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdf3f754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train :  [[2]\n",
      " [4]\n",
      " [1]\n",
      " [5]]\n",
      "y train :  [ 80000 150000  50000 200000]\n",
      "x test :  [[6]\n",
      " [3]]\n",
      "y test :  [250000 110000]\n",
      "Coefficients :  [37000.]\n",
      "Intercept :  9000.0\n"
     ]
    }
   ],
   "source": [
    "#slip1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "Data = {'Position ': ['CEO','charman','director','senior manager','junior manager','intern'],\n",
    "       'Level':[1,2,3,4,5,6],'Salary':[50000,80000,110000,150000,200000,250000]\n",
    "       }\n",
    "df = pd.DataFrame(Data)\n",
    "\n",
    "x=df.iloc[:,1:2].values\n",
    "y=df.iloc[:,2].values\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "\n",
    "print(\"x train : \",x_train)\n",
    "print(\"y train : \",y_train)\n",
    "print(\"x test : \",x_test)\n",
    "print(\"y test : \",y_test)\n",
    "\n",
    "Regressor = LinearRegression()\n",
    "Regressor.fit(x_train,y_train)\n",
    "\n",
    "print(\"Coefficients : \",Regressor.coef_)\n",
    "print(\"Intercept : \",Regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0015f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train :  [[2]\n",
      " [4]\n",
      " [1]\n",
      " [5]]\n",
      "y train : [ 50000 150000  25000 200000]\n",
      "x test : [[6]\n",
      " [3]]\n",
      "y test : [250000 100000]\n",
      "coefficint :  [45000.]\n",
      "Intercept :  -28749.99999999997\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = {'Positions ': ['CEO','chairman','manager','employee','intern','staff'],\n",
    "        'Level': [1,2,3,4,5,6],'Salary ': [25000,50000,100000,150000,200000,250000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "x = df.iloc[:,1:2].values\n",
    "y=df.iloc[:,2].values\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "\n",
    "print(\"X train : \",x_train)\n",
    "print(\"y train :\",y_train)\n",
    "print(\"x test :\",x_test)\n",
    "print(\"y test :\" ,y_test)\n",
    "\n",
    "rg = LinearRegression()\n",
    "rg.fit(x_train,y_train)\n",
    "\n",
    "print(\"coefficint : \",rg.coef_)\n",
    "print(\"Intercept : \",rg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48b1a35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train    Yrsexp : \n",
      "9         10\n",
      "1          2\n",
      "6          7\n",
      "7          8\n",
      "3          4\n",
      "0          1\n",
      "5          6\n",
      "ytrain 9    55000\n",
      "1    15000\n",
      "6    40000\n",
      "7    45000\n",
      "3    30000\n",
      "0    10000\n",
      "5    35000\n",
      "Name: salary, dtype: int64\n",
      "ytest 2    20000\n",
      "8    50000\n",
      "4    25000\n",
      "Name: salary, dtype: int64\n",
      "xtest    Yrsexp : \n",
      "2          3\n",
      "8          9\n",
      "4          5\n",
      " coefficient :  [4887.89237668]\n",
      "Intercept :  6322.869955156952\n"
     ]
    }
   ],
   "source": [
    "# slip2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = {'Yrsexp : ':[1,2,3,4,5,6,7,8,9,10],'salary':[10000,15000,20000,30000,25000,35000,40000,45000,50000,55000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "x=df.iloc[:,0:1]\n",
    "y=df.iloc[:,1]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "\n",
    "print(\"x train\",x_train)\n",
    "print(\"ytrain\",y_train)\n",
    "print(\"ytest\",y_test)\n",
    "print(\"xtest\",x_test)\n",
    "\n",
    "rg = LinearRegression()\n",
    "rg.fit(x_train,y_train)\n",
    "\n",
    "print(\" coefficient : \",rg.coef_)\n",
    "print(\"Intercept : \",rg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08a072c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train : \n",
      " [['female' 34 28000]\n",
      " ['female' 45 35000]\n",
      " ['male' 51 100000]\n",
      " ['female' 27 98000]\n",
      " ['male' 16 10000]\n",
      " ['male' 23 20000]\n",
      " ['female' 42 40000]]\n",
      "x test : \n",
      " [['female' 32 26000]\n",
      " ['male' 61 76000]\n",
      " ['male' 36 55000]]\n",
      "y train : \n",
      " [0 1 0 1 1 0 1]\n",
      "y test : \n",
      " [0 0 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'female'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my test : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,y_test)\n\u001b[0;32m     26\u001b[0m rg \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m rg\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[0;32m     29\u001b[0m obs \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m29\u001b[39m,\u001b[38;5;241m45000\u001b[39m]]\n\u001b[0;32m     30\u001b[0m pre \u001b[38;5;241m=\u001b[39m rg\u001b[38;5;241m.\u001b[39mpredict(obs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1205\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1207\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1208\u001b[0m     X,\n\u001b[0;32m   1209\u001b[0m     y,\n\u001b[0;32m   1210\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1212\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1213\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1214\u001b[0m )\n\u001b[0;32m   1215\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'female'"
     ]
    }
   ],
   "source": [
    "#slip3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "user={'userid':[1,2,3,4,5,6,7,8,9,10],\n",
    "      'gender':['male','female','female','male','male','female','male','female','male','female'],\n",
    "      'age':[23,45,32,16,36,42,51,27,61,34],\n",
    "      'salary ':[20000,35000,26000,10000,55000,40000,100000,98000,76000,28000],\n",
    "      'purchased':[0,1,0,1,1,1,0,1,0,0]}\n",
    "\n",
    "df = pd.DataFrame(user)\n",
    "\n",
    "x=df.iloc[:,1:4].values\n",
    "y=df.iloc[:,4].values\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "\n",
    "print(\"x train : \\n\",x_train)\n",
    "print(\"x test : \\n\",x_test)\n",
    "print(\"y train : \\n\",y_train)\n",
    "print(\"y test : \\n\",y_test)\n",
    "\n",
    "rg = LogisticRegression(random_state=0)\n",
    "rg.fit(x_train,y_train)\n",
    "\n",
    "obs = [[0,29,45000]]\n",
    "pre = rg.predict(obs)\n",
    "print(pre)\n",
    "\n",
    "obsrv=[[0,32,27000],[2,56,80000],[5,41,52000]]\n",
    "pred = rg.predict(obsrv)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1611671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.94291125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#slip4\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "fish_species=['tuna','salmon','trout','bass','sardine','cod','mackerel']\n",
    "weights=[]\n",
    "for i in range(50):\n",
    "    fish_weight=[]\n",
    "    for j in range(7):\n",
    "        weight=random.randint(1,20)\n",
    "        fish_weight.append(weight)\n",
    "        weights.append(fish_weight)\n",
    "        \n",
    "df = pd.DataFrame(weights,columns=fish_species)\n",
    "\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "new_fish = [[10,12,15,7,4,8]]\n",
    "pred_weight = model.predict(new_fish)\n",
    "\n",
    "print(pred_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38fb9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.72581959]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "fish_species=['cod','tuna','bass','salmon','trout','sardine','marckel']\n",
    "weights=[]\n",
    "\n",
    "for i in range(50):\n",
    "    fish_weight=[]\n",
    "    for i in range(7):\n",
    "        weight=random.randint(1,20)\n",
    "        fish_weight.append(weight)\n",
    "        weights.append(fish_weight)\n",
    "        \n",
    "df = pd.DataFrame(weights,columns=fish_species)\n",
    "\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x,y)\n",
    "\n",
    "new_fish=[[10,12,7,8,15,4]]\n",
    "pred = lr.predict(new_fish)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2abf0f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical details of iris setosa\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count           50.00000         50.000000          50.000000   \n",
      "mean             5.00600          3.428000           1.462000   \n",
      "std              0.35249          0.379064           0.173664   \n",
      "min              4.30000          2.300000           1.000000   \n",
      "25%              4.80000          3.200000           1.400000   \n",
      "50%              5.00000          3.400000           1.500000   \n",
      "75%              5.20000          3.675000           1.575000   \n",
      "max              5.80000          4.400000           1.900000   \n",
      "\n",
      "       petal width (cm)  target  \n",
      "count         50.000000    50.0  \n",
      "mean           0.246000     0.0  \n",
      "std            0.105386     0.0  \n",
      "min            0.100000     0.0  \n",
      "25%            0.200000     0.0  \n",
      "50%            0.200000     0.0  \n",
      "75%            0.300000     0.0  \n",
      "max            0.600000     0.0  \n",
      "Statistical details of iris versicolor\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count          50.000000         50.000000          50.000000   \n",
      "mean            5.936000          2.770000           4.260000   \n",
      "std             0.516171          0.313798           0.469911   \n",
      "min             4.900000          2.000000           3.000000   \n",
      "25%             5.600000          2.525000           4.000000   \n",
      "50%             5.900000          2.800000           4.350000   \n",
      "75%             6.300000          3.000000           4.600000   \n",
      "max             7.000000          3.400000           5.100000   \n",
      "\n",
      "       petal width (cm)  target  \n",
      "count         50.000000    50.0  \n",
      "mean           1.326000     1.0  \n",
      "std            0.197753     0.0  \n",
      "min            1.000000     1.0  \n",
      "25%            1.200000     1.0  \n",
      "50%            1.300000     1.0  \n",
      "75%            1.500000     1.0  \n",
      "max            1.800000     1.0  \n",
      "Statistical details of iris verginica\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count           50.00000         50.000000          50.000000   \n",
      "mean             6.58800          2.974000           5.552000   \n",
      "std              0.63588          0.322497           0.551895   \n",
      "min              4.90000          2.200000           4.500000   \n",
      "25%              6.22500          2.800000           5.100000   \n",
      "50%              6.50000          3.000000           5.550000   \n",
      "75%              6.90000          3.175000           5.875000   \n",
      "max              7.90000          3.800000           6.900000   \n",
      "\n",
      "       petal width (cm)  target  \n",
      "count          50.00000    50.0  \n",
      "mean            2.02600     2.0  \n",
      "std             0.27465     0.0  \n",
      "min             1.40000     2.0  \n",
      "25%             1.80000     2.0  \n",
      "50%             2.00000     2.0  \n",
      "75%             2.30000     2.0  \n",
      "max             2.50000     2.0  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[0;32m     31\u001b[0m pred \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m---> 33\u001b[0m accuracy\u001b[38;5;241m=\u001b[39maccuracy_score(y_test,pred)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(accurcay)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#slip 5\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "\n",
    "df['target']=iris.target\n",
    "\n",
    "print(\"Statistical details of iris setosa\")\n",
    "print(df[df['target']==0].describe())\n",
    "\n",
    "print(\"Statistical details of iris versicolor\")\n",
    "print(df[df['target']==1].describe())\n",
    "\n",
    "print(\"Statistical details of iris verginica\")\n",
    "print(df[df['target']==2].describe())\n",
    "\n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "pred = lr.predict(x_test)\n",
    "\n",
    "accuracy=accuracy_score(y_test,pred)\n",
    "print(accurcay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "552f64c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransactionEncoder\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrequent_patterns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apriori,association_rules\n\u001b[0;32m      5\u001b[0m tid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbread\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmilk\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;241m2\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbread\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiaper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meggs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;241m3\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmilk\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiaper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoke\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;241m4\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbread\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmilk\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiaper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeer\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;241m5\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbread\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmilk\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiaper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoke\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori,association_rules\n",
    "\n",
    "tid = {1:[\"bread\",\"milk\"],2:[\"bread\",\"diaper\",\"beer\",\"eggs\"],3:[\"milk\",\"diaper\",\"beer\",\"coke\"],4:[\"bread\",\"milk\",\"diaper\",\"beer\"],5:[\"bread\",\"milk\",\"diaper\",\"coke\"]}\n",
    "\n",
    "transactions =[]\n",
    "\n",
    "for key,value in tid.items():\n",
    "    transactions.append(value)\n",
    "    \n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transfrom(transactions)\n",
    "\n",
    "df = pd.DataFrame(te_ary,columns=te.columns_)\n",
    "\n",
    "min_sup_values=[0.2,0.4,0.6]\n",
    "\n",
    "for min_sup in min_sup_values:\n",
    "    fre_itemset=apriori(df,min_sup,use_colnames=True)\n",
    "    rules = association_rules(fre_itemset,metric=\"confidence\",min_threshold=0.7)\n",
    "    print(\"Min_sup\\n\",min_sup)\n",
    "    print(\"Freq_itemset\\n\",fre_itemset)\n",
    "    print(\"Association rules\\n\",rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518f110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
